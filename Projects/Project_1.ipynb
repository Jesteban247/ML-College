{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "tol2kfqvy8ca",
        "iPTn8R7RyvfC"
      ],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNjn3p9Ng7oB8Lha1mUdhla",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jesteban247/ML-College/blob/main/Projects/Project_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "tol2kfqvy8ca"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B0Ss6ZQhowyF"
      },
      "outputs": [],
      "source": [
        "# Cell 1: Install required packages and libraries\n",
        "!git clone https://github.com/rapidsai/rapidsai-csp-utils.git\n",
        "!python rapidsai-csp-utils/colab/pip-install.py\n",
        "!pip install -q dagshub mlflow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: Import necessary libraries\n",
        "import cudf\n",
        "import zipfile\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Input, Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "import time\n",
        "from tensorflow.keras.utils import plot_model\n",
        "import mlflow\n",
        "import mlflow.tensorflow\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import dagshub"
      ],
      "metadata": {
        "id": "rIXik4Fho1QX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3: Check GPU Availability\n",
        "def check_gpu():\n",
        "    gpus = tf.config.list_physical_devices('GPU')\n",
        "    if gpus:\n",
        "        print(\"GPUs available:\")\n",
        "        for gpu in gpus:\n",
        "            print(f\"- {gpu}\")\n",
        "    else:\n",
        "        print(\"No GPUs detected.\")\n",
        "\n",
        "check_gpu()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZ6nl0yoo674",
        "outputId": "f6ab269e-9c1c-4420-a91a-3298255b3e17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPUs available:\n",
            "- PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4: GPU details\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1G9BXkco-zj",
        "outputId": "595f2ff3-cabd-4f58-b427-9b1032873225"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Sep 12 05:59:24 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   43C    P8               9W /  70W |      3MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5: Download and Extract Dataset\n",
        "!kaggle datasets download -d nonrice/clash-royale-battles-upper-ladder-december-2021\n",
        "zip_file_path = '/content/clash-royale-battles-upper-ladder-december-2021.zip'\n",
        "extraction_folder = '/content/clash_royale_dataset/'\n",
        "os.makedirs(extraction_folder, exist_ok=True)\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extraction_folder)\n",
        "print(\"Dataset successfully extracted!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pM5YE1k8pBf7",
        "outputId": "5f3e51af-46b1-4501-a8d8-287db04c1546"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/nonrice/clash-royale-battles-upper-ladder-december-2021\n",
            "License(s): CC-BY-SA-4.0\n",
            "Downloading clash-royale-battles-upper-ladder-december-2021.zip to /content\n",
            " 81% 9.00M/11.1M [00:01<00:00, 11.2MB/s]\n",
            "100% 11.1M/11.1M [00:01<00:00, 8.23MB/s]\n",
            "Dataset successfully extracted!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6: Load Dataset using RAPIDS cuDF\n",
        "data_ord = cudf.read_csv('/content/clash_royale_dataset/data_ord.csv')\n",
        "data_ord.drop(data_ord.columns[0], axis=1, inplace=True)\n",
        "cardlist = cudf.read_csv('/content/clash_royale_dataset/cardlist.csv')\n",
        "cardlist.drop(cardlist.columns[0], axis=1, inplace=True)\n",
        "\n",
        "# Create Binary Features\n",
        "cardlist['p_1'] = cardlist['card'] + '_p1'\n",
        "cardlist['p_2'] = cardlist['card'] + '_p2'\n",
        "columns = cardlist['p_1'].to_arrow().to_pylist() + cardlist['p_2'].to_arrow().to_pylist()\n",
        "df = cudf.DataFrame(index=cudf.Series(range(data_ord.shape[0])), columns=columns).fillna(0)\n",
        "\n",
        "p1_indices = list(range(8))\n",
        "p2_indices = list(range(8, 16))\n",
        "positions_p1 = data_ord.iloc[:, p1_indices].astype(int)\n",
        "positions_p2 = data_ord.iloc[:, p2_indices].astype(int) + 106\n",
        "\n",
        "binary_df_p1 = cudf.DataFrame({cardlist['p_1'][i]: (positions_p1 == i).any(axis=1).astype(int) for i in range(len(cardlist))})\n",
        "binary_df_p2 = cudf.DataFrame({cardlist['p_2'][i]: (positions_p2 == i + 106).any(axis=1).astype(int) for i in range(len(cardlist))})\n",
        "df = cudf.concat([binary_df_p1, binary_df_p2], axis=1)\n",
        "\n",
        "# Prepare Features and Target\n",
        "X = df\n",
        "y = data_ord['outcome']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Show Data Types\n",
        "print(f\"Type of X: {type(X)}\")\n",
        "print(f\"Type of y: {type(y)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2y4EaoZipCmv",
        "outputId": "6200b34f-2cda-400c-ad7f-5e3e53cfe272"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type of X: <class 'cudf.core.dataframe.DataFrame'>\n",
            "Type of y: <class 'cudf.core.series.Series'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "iPTn8R7RyvfC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 7: Convert to TensorFlow Dataset\n",
        "def to_tf_dataset(X, y, batch_size=32):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((X.to_pandas().values, y.to_pandas().values))\n",
        "    dataset = dataset.shuffle(buffer_size=len(X))\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "    return dataset\n",
        "\n",
        "train_dataset = to_tf_dataset(X_train, y_train)\n",
        "test_dataset = to_tf_dataset(X_test, y_test)\n",
        "\n",
        "# Show TensorFlow Dataset Types\n",
        "print(f\"Type of train_dataset: {type(train_dataset)}\")\n",
        "print(f\"Type of test_dataset: {type(test_dataset)}\")\n"
      ],
      "metadata": {
        "id": "PzS5Y83DpHVW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 8: Build the TensorFlow Model\n",
        "def build_tf_model(input_dim, num_hidden_layers, num_neurons_per_layer, learning_rate):\n",
        "    model = Sequential()\n",
        "    model.add(Input(shape=(input_dim,)))\n",
        "    model.add(Dense(num_neurons_per_layer, activation='relu'))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    for _ in range(num_hidden_layers - 1):\n",
        "        model.add(Dense(num_neurons_per_layer, activation='relu'))\n",
        "        model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "lO1c8QF0qH-K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 9: Initialize DagsHub with MLflow tracking\n",
        "dagshub.init(repo_owner='Jesteban247', repo_name='Clash-Royale-Experiment', mlflow=True)\n",
        "\n",
        "# Set up MLflow experiment in the DagsHub repo\n",
        "mlflow.set_experiment(\"Clash Royale Experiment\")\n",
        "\n",
        "# Enable MLflow Autologging\n",
        "mlflow.autolog()"
      ],
      "metadata": {
        "id": "Cwe19orKqKoY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 10: Function to train and evaluate the model\n",
        "def train_and_evaluate_model(input_dim, num_hidden_layers, num_neurons_per_layer, epochs, learning_rate):\n",
        "    # End any active MLflow run before starting a new one\n",
        "    if mlflow.active_run() is not None:\n",
        "        mlflow.end_run()\n",
        "\n",
        "    try:\n",
        "        # Start a new MLflow run\n",
        "        with mlflow.start_run():\n",
        "            # Build the TensorFlow model\n",
        "            tf_model = build_tf_model(input_dim, num_hidden_layers, num_neurons_per_layer, learning_rate)\n",
        "\n",
        "            # Setup TensorBoard logging\n",
        "            log_dir = \"results/runs\"  # Directory for TensorBoard logs\n",
        "            tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "\n",
        "            # Log only specific parameters\n",
        "            mlflow.log_param(\"num_hidden_layers\", num_hidden_layers)\n",
        "            mlflow.log_param(\"num_neurons_per_layer\", num_neurons_per_layer)\n",
        "            mlflow.log_param(\"epochs\", epochs)\n",
        "            mlflow.log_param(\"learning_rate\", learning_rate)\n",
        "\n",
        "            print(f\"Starting training with parameters: \"\n",
        "                  f\"num_hidden_layers={num_hidden_layers}, \"\n",
        "                  f\"num_neurons_per_layer={num_neurons_per_layer}, \"\n",
        "                  f\"epochs={epochs}, \"\n",
        "                  f\"learning_rate={learning_rate}\")\n",
        "\n",
        "            # Train the model\n",
        "            start_time = time.time()\n",
        "            early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
        "            history = tf_model.fit(\n",
        "                train_dataset,\n",
        "                epochs=epochs,\n",
        "                validation_data=test_dataset,\n",
        "                callbacks=[early_stopping, tensorboard_callback]\n",
        "            )\n",
        "            tf_training_time = time.time() - start_time\n",
        "\n",
        "            # Print training details\n",
        "            print(f\"Training completed in {tf_training_time:.2f} seconds.\")\n",
        "            print(f\"Final training accuracy: {history.history['accuracy'][-1]:.4f}\")\n",
        "            print(f\"Final training loss: {history.history['loss'][-1]:.4f}\")\n",
        "            print(f\"Final validation accuracy: {history.history['val_accuracy'][-1]:.4f}\")\n",
        "            print(f\"Final validation loss: {history.history['val_loss'][-1]:.4f}\")\n",
        "\n",
        "            # Evaluate the model\n",
        "            start_time = time.time()\n",
        "            loss, accuracy = tf_model.evaluate(test_dataset)\n",
        "            tf_evaluation_time = time.time() - start_time\n",
        "\n",
        "            # Print evaluation details\n",
        "            print(f\"Evaluation completed in {tf_evaluation_time:.2f} seconds.\")\n",
        "            print(f\"Test accuracy: {accuracy:.4f}\")\n",
        "            print(f\"Test loss: {loss:.4f}\")\n",
        "\n",
        "            # Log metrics in MLflow (autologging will handle other details)\n",
        "            mlflow.log_metric(\"training_time\", tf_training_time)\n",
        "            mlflow.log_metric(\"evaluation_time\", tf_evaluation_time)\n",
        "\n",
        "        print(f\"Training done! TensorBoard logs saved at: {log_dir}\")\n",
        "        print(f\"View run details at: {mlflow.get_artifact_uri()}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        # Optionally, you can end the run if it is not ended\n",
        "        if mlflow.active_run() is not None:\n",
        "            mlflow.end_run()\n"
      ],
      "metadata": {
        "id": "apYFhGRNqPRe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 11: Example Run\n",
        "train_and_evaluate_model(input_dim=X_train.shape[1],\n",
        "                         num_hidden_layers=4,\n",
        "                         num_neurons_per_layer=128,\n",
        "                         epochs=2,\n",
        "                         learning_rate=0.0005)"
      ],
      "metadata": {
        "id": "isOmpOVKqScL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test 2\n",
        "train_and_evaluate_model(input_dim=X_train.shape[1],\n",
        "                         num_hidden_layers=3,\n",
        "                         num_neurons_per_layer=64,\n",
        "                         epochs=5,\n",
        "                         learning_rate=0.001)"
      ],
      "metadata": {
        "id": "KqC1yvcMrjUT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 12: Launch TensorBoard for Visualization (after MLflow logging)\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir results/runs"
      ],
      "metadata": {
        "id": "pCIwTWX1qjp5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "THsGME-VyxXE"
      }
    },
    {
      "source": [
        "import cuml\n",
        "from cuml.linear_model import LogisticRegression\n",
        "import time\n",
        "\n",
        "# Initialize and fit the Logistic Regression model\n",
        "log_reg = LogisticRegression()\n",
        "\n",
        "# Convert X_train to float32\n",
        "X_train = X_train.astype('float32')\n",
        "# Convert X_test to float32\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "# Train the model and measure time\n",
        "start_time = time.time()\n",
        "log_reg.fit(X_train, y_train)\n",
        "training_time = time.time() - start_time\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = log_reg.score(X_test, y_test)\n",
        "\n",
        "# Print results\n",
        "print(f\"Training time: {training_time:.2f} seconds\")\n",
        "print(f\"Test accuracy: {accuracy:.4f}\")"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbtxnawv5Y03",
        "outputId": "a5ab23c5-9356-4dbb-de37-76aaca5a5983"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training time: 0.49 seconds\n",
            "Test accuracy: 0.5588\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cuml\n",
        "from cuml.naive_bayes import GaussianNB\n",
        "import time\n",
        "\n",
        "# Initialize the Naive Bayes model\n",
        "nb = GaussianNB()\n",
        "\n",
        "# Train the model and measure time\n",
        "start_time = time.time()\n",
        "nb.fit(X_train, y_train)\n",
        "training_time = time.time() - start_time\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = nb.score(X_test, y_test)\n",
        "\n",
        "# Print results\n",
        "print(f\"Training time: {training_time:.2f} seconds\")\n",
        "print(f\"Test accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fl5cGacO5rKD",
        "outputId": "b2ca941e-7a56-4347-ec7f-cad8ee460771"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training time: 0.19 seconds\n",
            "Test accuracy: 0.5360\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1: Import Required Libraries\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "import time\n",
        "import pandas as pd\n",
        "\n",
        "# Cell 2: Convert to Pandas DataFrames/Series (if needed)\n",
        "X_train_pd = X_train.to_pandas()\n",
        "X_test_pd = X_test.to_pandas()\n",
        "y_train_pd = y_train.to_pandas()\n",
        "y_test_pd = y_test.to_pandas()\n",
        "\n",
        "# Cell 3: Train Logistic Regression Model and Measure Time\n",
        "start_time = time.time()\n",
        "\n",
        "# Initialize and fit the Logistic Regression model\n",
        "log_reg = LogisticRegression(max_iter=1000)\n",
        "log_reg.fit(X_train_pd, y_train_pd)\n",
        "\n",
        "training_time = time.time() - start_time\n",
        "\n",
        "# Predict and evaluate the model\n",
        "y_pred = log_reg.predict(X_test_pd)\n",
        "accuracy = accuracy_score(y_test_pd, y_pred)\n",
        "\n",
        "# Print results\n",
        "print(f\"Training time: {training_time:.2f} seconds\")\n",
        "print(f\"Test accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pi9LDlbg3Q8P",
        "outputId": "fe73daa1-0ae2-4cbd-9eb8-01005cc52519"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training time: 24.04 seconds\n",
            "Test accuracy: 0.5587\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Analysis of Clash Royale Victory Prediction Based on Cards**\n",
        "\n",
        "I've conducted an analysis to predict the win or loss in Clash Royale based on the cards used by players. Here is a summary of the process and findings:\n",
        "\n",
        "### Data Processing\n",
        "\n",
        "1. **Data Preparation**: The data has been processed and is already in binary format. Each player has a feature vector of 212 dimensions, representing the 106 possible cards in the game, with each card being binary (present or not).\n",
        "\n",
        "2. **Transformations and Cleaning**:\n",
        "   - **Transformations**: The data is in binary format, and no additional cleaning is necessary.\n",
        "   - **Normalization and Dimensionality Reduction**: Given the data size, which isn't excessively large, dimensionality reduction techniques like PCA were not applied. The processing using CUDA libraries for linear regression and Naive Bayes was efficient and took minimal time.\n",
        "\n",
        "### Model Performance\n",
        "\n",
        "- The highest accuracy achieved so far is around 60%. While this is a reasonable performance considering the complexity of the task, it indicates that predicting the outcome based solely on card features has its limitations.\n",
        "\n",
        "### Conclusion\n",
        "\n",
        "Considering the current results and constraints, I believe there is limited scope for significant improvement. Achieving an accuracy of 95% or higher is highly unlikely with the current feature set and methods. The models are performing reasonably well, but further enhancements would require additional data or features, such as integrating external information from the Clash Royale API."
      ],
      "metadata": {
        "id": "ryZPVRds9dPe"
      }
    }
  ]
}